<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Deduplicating EveryAction &mdash; Data Engineering the Left</title>
  <meta name="author" content="Austin Weisgrau">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="https://austinweisgrau.github.io/favicon.png" rel="icon">

  <link href="https://austinweisgrau.github.io/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://austinweisgrau.github.io/">Data Engineering the Left</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<ul class="main-navigation">
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Deduplicating EveryAction</h1>
    <p class="meta">
<time datetime="2024-07-02T00:00:00-07:00" pubdate>Tue 02 July 2024</time>    </p>
</header>

  <div class="entry-content"><p>Like most progressive political organizations, Working Families Party
(<span class="caps">WFP</span>) reluctantly uses EveryAction, the volunteer-management side of
<span class="caps">NGPVAN</span>, as our <span class="caps">CRM</span> for keeping track of our activists and
donors. EveryAction has many issues, support is difficult to access,
and its issues are unlikely to dramatically improve since its recent
acquisition by private equity and subsequent mass&nbsp;layoffs.</p>
<p>One common issue with EveryAction is the proliferation of duplicate
contacts. Staff working with EveryAction will search for a contact and
notice that two or more contacts for the same person seem to
exist. This creates a problem with getting accurate metrics out of
EveryAction and also introduces confusing workflow issues for any
staff who want to add or update contact attributes. Which contact
should be updated? Pick either one? Update&nbsp;both?</p>
<p>Contacts can be manually merged in the EveryAction web app, but the
process is slow and untenable if duplicates exist at scale. And for
any organization that uses EveryAction for several years or longer,
duplicates can certainly go to scale. At <span class="caps">WFP</span> we estimate that
somewhere between 5%-10% of our EveryAction contacts are&nbsp;duplicates.</p>
<p>Bonterra, the organization behind EveryAction, is aware of the common
issue with duplication and offers a paid service to deduplicate your
data for you. The fee for the service is exorbitant and a questionable
offering when dealing with duplicates is arguably more of a bug in the
product than a feature to be upsold&nbsp;on.</p>
<p>We decided to tackle deduplicating our data ourselves and want to
share our process and learnings with the rest of the progressive
organizations who are still locked in to this&nbsp;product. </p>
<p>To tackle the proliferation of duplicates in EveryAction, we needed to
answer a few key&nbsp;questions:</p>
<ol>
<li>Where are the duplicates coming from? // How can we mitigate the
   creation of new&nbsp;duplicates?</li>
<li>Which contacts are duplicates? // How can we match and merge
   existing&nbsp;duplicates?</li>
</ol>
<h2>Whence&nbsp;??</h2>
<h3>Where are the duplicates coming&nbsp;from?</h3>
<p><em>Before we dive in, I will note that I did this engineering work and wrote this blog post about a year ago, and some small things have changed with EveryAction’s duplicate handling in that time. Some of the details I found through trial and error may not still behave in exactly the same way, although most of the behavior described here should still&nbsp;hold.</em></p>
<p>When data is loaded into EveryAction, EveryAction attempts to validate the new data with an existing contact record using one of four combinations of data&nbsp;fields.</p>
<ul>
<li>first name, last name, date of&nbsp;birth</li>
<li>first name, last name, phone&nbsp;number</li>
<li>first name, last name,&nbsp;email</li>
<li>first name, last name, street number, street name,&nbsp;zipcode</li>
</ul>
<p>If a match is found on any of those sets of attributes, EveryAction
will load associated data to that existing matched contact. Good! If
no match can be found, a new contact is created. Makes&nbsp;sense.</p>
<p>There are a few bugs in this process, however, that cause issues with&nbsp;matching.</p>
<p>If a phone or email that can&#8217;t be parsed as valid are provided in the
set of contact attributes, EveryAction will fail to make a match, even
if there are enough other attributes available to make a&nbsp;match.</p>
<p>If none of the preferred supplementary contact attributes are
available, EveryAction will make a new contact. If you only ever
obtain first names and last names for certain contacts and regularly
load that data into EveryAction, you will make duplicates of those
same contacts each and every&nbsp;time.</p>
<p>And of course, people&#8217;s contact details and even their names change
over time, typos arise all the time,&nbsp;etc.</p>
<h3>How can we mitigate the creation of new&nbsp;duplicates?</h3>
<p>To mitigate the creation of new duplicates, we needed to improve the
performance of the &#8220;matching&#8221; step that happens before data is loaded
onto a matched or created&nbsp;contact.</p>
<p>Data is loaded into our EveryAction instance in three&nbsp;ways:</p>
<ol>
<li>Some tools like Mobilize have built-in integrations with
   EveryAction and load data&nbsp;directly.</li>
<li>We use the <span class="caps">API</span> to programmatically sync data from other
   platforms (like ActBlue and Spoke) that don&#8217;t have direct&nbsp;integrations.</li>
<li>Sometimes staff do a bulk upload manually through the web&nbsp;app. </li>
</ol>
<p>I assume that all three methods use the same logic to make matches,
but I&#8217;ve only personally verified the behavior of the <span class="caps">API</span>.</p>
<p>The EveryAction <span class="caps">API</span> offers two endpoints for finding contact matches.
- <code>/find</code> will search for a match, and raise various errors on failure
  to find a match.
- <code>/findOrCreate</code> will search for a match, and create a new contact if
  no match is found. This endpoint always returns a contact, and
  there&#8217;s no simple way to know if the contact was a match or is a new&nbsp;creation.</p>
<p><code>/findOrCreate</code> is very convenient for getting a sync up and
running. Many of our legacy syncs to EveryAction used that
endpoint. However, to mitigate the creation of new duplicates, we need
to improve the default matching behavior. We can achieve this
improvement by separating the &#8220;find&#8221; and &#8220;create&#8221; steps, and adding
more flexibility into the matching logic before reverting to new contact&nbsp;creation.</p>
<p>In pseudo-code, this looks like moving&nbsp;from:</p>
<div class="highlight"><pre><span></span><code><span class="n">contact_data</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>
<span class="n">van_id</span> <span class="o">=</span> <span class="n">find_or_create_van_id</span><span class="p">(</span><span class="n">contact_data</span><span class="p">)</span>
</code></pre></div>

<p>to</p>
<div class="highlight"><pre><span></span><code><span class="n">contact_data</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>
<span class="n">van_id</span> <span class="o">=</span> <span class="n">find_van_id</span><span class="p">(</span><span class="n">contact_data</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">van_id</span><span class="p">:</span>
    <span class="n">van_id</span> <span class="o">=</span> <span class="n">try_harder_to_find_van_id</span><span class="p">(</span><span class="n">contact_data</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">van_id</span><span class="p">:</span>
    <span class="n">van_id</span> <span class="o">=</span> <span class="n">create_van_id</span><span class="p">(</span><span class="n">contact_data</span><span class="p">)</span>
</code></pre></div>

<p>If we don&#8217;t default to creating a new contact whenever EveryAction
fails to find a match, we have the opportunity to add some more
flexible and intelligent matching logic into the&nbsp;process.</p>
<p>There are several strategies we&#8217;ve developed that seem to make many
reliable matches that EveryAction fails to make. We are continuing to
monitor the creation of new contacts to identify other heuristics that
can be used in a function like <code>try_harder_to_find_van_id()</code>.</p>
<ul>
<li>If a middle initial or middle name gets input as part of a
   first name, EveryAction will fail to make a match. e.g. &#8220;Barbara
   E. Walters, 858-555-5555&#8221; will not match to &#8220;Barbara Walters,
   858-555-5555&#8221;. Removing characters from a first name after an
   initial space can more reliably match&nbsp;contacts. </li>
<li>Apostrophes and quote marks are not reliably parsed by source
   platforms or EveryAction. e.g. &#8220;Mark O&#8217;Donnell, 619-555-5555&#8221;
   will not match with &#8220;Mark ODonnell, 619-555-5555&#8221; or &#8220;Mark
   O`Donnell, 619-555-5555&#8221;. Removing apostrophes and quote marks from
   names seems to improve&nbsp;matching.</li>
<li>Cleaning and validating phone numbers, emails, and street numbers
   and zipcodes before attempting to make a match improves matching.
   e.g. &#8220;John Green, 750-555-3499a, jgreen @hotmail.co&#8221; will not
   normally match to &#8220;John Green, 750-555-3499,&nbsp;jgreen@hotmail.com&#8221;</li>
</ul>
<p>A working example version of a python function built on top of the
 <code>parsons</code> package that implements the logic described above can be
 seen&nbsp;here.</p>
<p>By cleaning and validating data and making other improvements to
matching heuristics, we can more reliably find matches to our source
data before defaulting to creating new&nbsp;contacts.</p>
<h2>Whomst&nbsp;??</h2>
<h3>Which contacts are&nbsp;duplicates?</h3>
<p>The problem of identifying records in a dataset that refer to the same
person is called &#8220;entity resolution,&#8221; or more specifically &#8220;identity
resolution&#8221; if your duplicated entities are&nbsp;people.</p>
<p>Identity resolution is a nearly universal data quality
issue. Depending on how data is gathered, it is usually very hard or
impossible to track individuals over time with complete
certainty. There are very few contact attributes that are not subject
to change over time. In the context of community organizing, we only
generally gather basic contact attributes like name, email, phone, and
address. All of those contact attributes are subject to change, and
sometimes frequent change. This makes matching contact data back up
into a consolidated list of individual persons&nbsp;difficult.</p>
<p>The problem of identifying which contacts in our data our duplicates
of each other is essentially a problem of identity&nbsp;resolution.</p>
<p>Luckily, because this is a common business problem, there are many
resources available to help address the issue. In particular, the free
and open source packages splink and zingg appeared promising to our
team. Both packages train and deploy machine learning models developed
from academic statistics research into identity&nbsp;resolution.</p>
<p>Machine learning models can make powerful, accurate predictions, but
may be non-deterministic and can obscure the logic used under-the-hood
to make their predictions. Without some kind of baseline, it would be
hard for us to tell how well these models were performing in
identifying duplicates in our data. To improve our understanding of
our problem, we first developed a series of <span class="caps">SQL</span> models to identify
duplicates according to a set of reliable, deterministic&nbsp;criteria.</p>
<h4><span class="caps">SQL</span>&nbsp;Models</h4>
<p>We made two sets of criteria for identifying duplicates at different
levels of confidence. &#8220;High confidence matches&#8221; were matches that we
felt so confident of, we were willing to merge without manual
review. &#8220;Medium confidence matches&#8221; are mostly duplicates, but contain
many false positives that we want to weed out with either manual
review or future revisions of our <span class="caps">SQL</span>&nbsp;models.</p>
<h5>High confidence&nbsp;matches</h5>
<p>Our high confidence criteria are based on the same criteria that
EveryAction uses. By design there should be few or zero duplicates on
the contact sets that EveryAction uses to make matches, but we found
about 3% of our contacts were duplicates on these canonical contact
attributes. (Our support contact at EveryAction thinks these are
likely due to ongoing or legacy bugs in the matching&nbsp;system).</p>
<p>We expand this set by cleaning and normalizing the contact attributes
before they are&nbsp;matched.</p>
<ul>
<li>Names are cleaned of all non-alphabet or space characters,
  trimmed of leading or trailing&nbsp;spaces</li>
<li>All characters are&nbsp;lower-cased</li>
<li>First names are reduced to the first word before a&nbsp;space</li>
</ul>
<p>This expanded set includes an additional ~0.3% of our total&nbsp;contacts.</p>
<h5>Medium confidence&nbsp;matches</h5>
<p>Our medium confidence criteria are a bit more expansive, and represent
different heuristics we developed based on looking through our data to
try and guess at what patterns were generating&nbsp;duplicates. </p>
<p>One very common pattern we noticed was contacts recorded with a first
initial as a first name. For example, &#8220;Barbara Smith, 555-555-5555&#8221;
may have a duplicate &#8220;B Smith,&nbsp;555-555-5555&#8221;.</p>
<p>Another common pattern we saw was a match in email usernames with
either a change or typo in email
domain. e.g. &#8220;barbsmith1972@yahoo.com&#8221; should match
&#8220;barbsmith1972@gmail.com&#8221; or&nbsp;&#8220;barbsmith1972@yahoo.co&#8221;.</p>
<p>This medium confidence model mimics the high confidence model, but
expands the match criteria to catch these first initial matches and
email username&nbsp;matches.</p>
<p>The other common pattern we catch in this model is matches on first
name and last name when these other contact attributes are all
null. As discussed above, when contact data with only first name and
last name are loaded to Every Action, a new contact is created every
time. We want to find and merge all such&nbsp;examples.</p>
<p>When we filter out overlaps with the high confidence model, this
medium confidence model finds an additional ~1% of our total&nbsp;contacts.</p>
<p>We do expect that some of these are false positives, and we want to
manually review all of these medium confidence matches before
programmatically merging&nbsp;them.</p>
<h5>Review</h5>
<p>Using these clear and deterministic criteria, we find that 3-4% of our
total contacts may be duplicates. Likely some portion of these are
false positives, but we also expect that we capture only a small
portion of the total duplicates that fail to match on these particular&nbsp;criteria.</p>
<p>The contacts identified by our <span class="caps">SQL</span> models give us a useful baseline
for comparison to our machine learning models. We can now estimate
their performance by comparing the overlap in contacts identified by&nbsp;each.</p>
<h4>Machine Learning&nbsp;Models</h4>
<p>While deterministic criteria may work for identifying many potential
duplicates, there are likely many more whose similarity is less easily
defined. Typos or changes across multiple fields may make comparison
difficult, and even with fuzzy matching we would still want to
differentially weight matches on different attributes. For example, an
exact match on date of birth is worth more than an exact match on&nbsp;zipcode.</p>
<p>The free and open source packages <a href="https://moj-analytical-services.github.io/splink/">splink</a> and <a href="https://www.zingg.ai/">zingg</a> were both
designed by data scientists with way more expertise than myself in
this problem area, and I&#8217;m inclined to trust that expertise and
implement their solutions to our identity resolution&nbsp;problem.</p>
<p>Both packages will take a dataset and output matches with confidence
scores. However, especially at first, I need to understand the
threshold at which the confidence of splink or zingg compares to my
own confidence. My initial approach is to send all matches above a
certain lower bound on confidence for manual review before
programmatically merging any of them. So I am treating all these
matches as &#8220;medium&nbsp;confidence&#8221;.</p>
<p>zingg looks a bit shinier, but splink looks easier to implement. zingg
and splink can both run on Apache Spark, but splink can also run on
duckdb. splink&#8217;s duckdb backend was impressively capable of running
predictions on our entire contacts table on my <span class="caps">16GB</span> <span class="caps">RAM</span> laptop in a
few&nbsp;minutes. </p>
<p>I set up an automated workflow for splink to run as a Prefect flow and
load its predictions to a redshift table. The splink model needs some
configuration to tell it which records to compare and how different
attributes should be compared. I based my configuration off their official
tutorial which some minor changes to reflect what we know about
EveryAction contact&nbsp;matches. </p>
<p>splink makes a <span class="caps">LOT</span> of predicted matches. We set our lower confidence
bound around 0.3 (on a scale from 0-1) and about 20% of the contacts
in our database are predicted to be duplicates at this level of
confidence. We expect many of these to be false positive matches, and
can select some subset of the top matches to manually&nbsp;validate.</p>
<p>|    | sql confidence   |   count |   splink max |   splink min |   splink mean |   splink median |\n|&#8212;-:|:&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-|&#8212;&#8212;&#8212;&#8212;:|&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-:|&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-:|&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;:|&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;:|\n|  0 | high             |   16562 |            1 |     0        |      0.997379 |        1        |\n|  1 | medium           |    8935 |            1 |     0        |      0.949009 |        0.958971 |\n|  2 | 0                | 6933193 |            1 |     0.300087 |      0.9452   |        0.944315&nbsp;|</p>
<p>This table compares how splink matches line up against our <span class="caps">SQL</span>
models. You can make your own conclusions, but I have a few key&nbsp;takeaways:</p>
<ul>
<li>splink makes several orders of magnitude more match predictions than
    my <span class="caps">SQL</span>&nbsp;models</li>
<li>splink confidence levels trend quite high, with a median of 94%
    confidence across all ~7 million predicted matches. Likely there
    is a huge difference in the quality of matches between 99%
    confidence and 94%&nbsp;confidence</li>
<li>splink confidence does seem to track with my <span class="caps">SQL</span> models. My high
    confidence <span class="caps">SQL</span> matches correspond to a median splink confidence of
    100%, down to 95.9% for my medium confidence <span class="caps">SQL</span> matches, and then
    down again to 94.4% for matches not identified by my <span class="caps">SQL</span>&nbsp;models.</li>
</ul>
<p>Some manual review of splink&#8217;s top matches that aren&#8217;t covered by my
<span class="caps">SQL</span> models validates the expected behavior. splink makes matches
between contacts that are clearly duplicated on manual review, but
don&#8217;t fall into the deterministic criteria I set in my <span class="caps">SQL</span>
models. Some of these&nbsp;scenarios:</p>
<ul>
<li>A nickname is used in one contact, making a match on firstname&nbsp;fail</li>
<li>A small typo exists in an email address or street&nbsp;address</li>
<li>A contact&#8217;s last name changed, perhaps due to&nbsp;marriage</li>
</ul>
<p>splink makes more match predictions than we can easily handle, and
seems to be performing well enough that we don&#8217;t need to bother
setting up&nbsp;zingg.</p>
<h3>Manual&nbsp;Validation</h3>
<p>Merging contacts is an irreversible operation, so it is important to
be quite confident about matches before executing a merge. For matches
identified by the high confidence <span class="caps">SQL</span> model defined above, we feel
confident about a programmatic merge. However, for all the matches
identified by our &#8220;medium confidence&#8221; <span class="caps">SQL</span> model, and all matches
identified by our splink implementation, we want to execute a manual
validation before&nbsp;merging. </p>
<p>To manually validate contacts, we have set up a web application that
pulls matches and all associated contact details. Contacts and their
details are displayed side by side, and a user selects whether the
match is valid, invalid, or unclear. The validation workflow is
somewhat boring and tedious, but quite fast. Using the web app, a
single person can validate 500-1000 matches in an&nbsp;hour. </p>
<p><img alt="Screenshot of validation app" src="https://austinweisgrau.github.io/images/validation_app.png"></p>
<p>Over time, using the web app to manually validate contacts helps to
generate new &#8220;high confidence&#8221; heuristics that can be used to identify
matches without needing a manual review step. For example, we may
realize we have a large number of contacts with first name &#8220;undefined&#8221;
and last name &#8220;undefined&#8221;, and we can investigate those further and
purge them from the database. Another example is that we have found
that contacts that are matched on first name and last name but have no 
additional contact details defined can be merged with high&nbsp;confidence.</p>
<h2>Whereunto&nbsp;??</h2>
<p>EveryAction should take responsibility for the management of duplicate
contacts as a critical feature in their <span class="caps">CRM</span>. However, in lieu of them
fixing this problem, it is possible for users with sufficient
engineering capacity to understand the problem and implement a fix on
our&nbsp;own. </p>
<p>We use <span class="caps">SQL</span> queries to identify matches at two levels of confidence,
and we use splink to identify another batch of duplicates. We feel
confident we can programmatically merge higher confidence <span class="caps">SQL</span> matches
without review, but we want to manually validate all the other
matches. We can use a web application to make the manual validation a
quick and easy process and manually validate thousands of potential
matches in just a few&nbsp;days. </p>
<p>High confidence and validated matches are accumulated in a database
table and staged for processing by a programmatic merge script. This
script iterates through each match and executes an <span class="caps">API</span> call to the
EveryAction <span class="caps">API</span> endpoint <code>/people/{vanid}/mergeInto</code>. </p>
<p>We run our <span class="caps">SQL</span> models, splink, and the programmatic merge on a weekly
basis to identify and merge duplicates. Manual validation happens on a
rolling basis and all validated contacts are aggregated and merged on
the next schedule merge&nbsp;flow.</p>
<p>If you want to know more about any of this, feel free to reach out. I
also tentatively plan on making an affordable plug-and-play version of
this application available to <span class="caps">TMC</span> members in early 2025 - let me know
if you might be interested in beta testing&nbsp;this.</p></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        Austin Weisgrau
    </span>
  </span>
<time datetime="2024-07-02T00:00:00-07:00" pubdate>Tue 02 July 2024</time>  <span class="categories">
    <a class='category' href='https://austinweisgrau.github.io/category/sharing.html'>sharing</a>
  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://austinweisgrau.github.io/an-orm-for-google-sheets.html">An ORM for Google Sheets</a>
      </li>
      <li class="post">
          <a href="https://austinweisgrau.github.io/tooling-for-big-data-transformations.html">Tooling for Big Data Transformations</a>
      </li>
      <li class="post">
          <a href="https://austinweisgrau.github.io/deduplicating-everyaction.html">Deduplicating EveryAction</a>
      </li>
      <li class="post">
          <a href="https://austinweisgrau.github.io/migrating-from-civis-to-prefect.html">Migrating from Civis to Prefect</a>
      </li>
      <li class="post">
          <a href="https://austinweisgrau.github.io/migrating-to-prefect-part-4-moving-a-script-from-civis-to-prefect.html">Migrating to Prefect, Part 4: Moving a Script from Civis to Prefect</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://austinweisgrau.github.io/category/learning.html">learning</a></li>
        <li><a href="https://austinweisgrau.github.io/category/sharing.html">sharing</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/in/austin-weisgrau-a784b042/" target="_blank">LinkedIn</a></li>
            <li><a href="https://github.com/austinweisgrau" target="_blank">GitHub</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2023&ndash;2025  Austin Weisgrau &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="https://austinweisgrau.github.io/theme/js/modernizr-2.0.js"></script>
  <script src="https://austinweisgrau.github.io/theme/js/ender.js"></script>
  <script src="https://austinweisgrau.github.io/theme/js/octopress.js" type="text/javascript"></script>
</body>
</html>