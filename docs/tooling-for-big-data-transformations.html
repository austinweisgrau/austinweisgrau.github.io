<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Tooling for Big Data Transformations &mdash; Data Engineering the Left</title>
  <meta name="author" content="Austin Weisgrau">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="/">Data Engineering the Left</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<ul class="main-navigation">
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Tooling for Big Data Transformations</h1>
    <p class="meta">
<time datetime="2024-10-29T00:00:00-07:00" pubdate>Tue 29 October 2024</time>    </p>
</header>

  <div class="entry-content"><p>Data teams sometimes struggle to find appropriate tooling for large
analytics workflows. A common pattern is for an analyst to work
primarily using the R tidyverse or Python pandas. This works fine for
awhile, but as the workflow scales up and the amount of data being
processed increases, eventually these tools struggle to keep up. Even
running these workflows on cloud servers with massive amounts of <span class="caps">CPU</span>
and <span class="caps">RAM</span> doesn&#8217;t scale&nbsp;well.</p>
<p>In my opinion, the only truly appropriate tooling for data
transformations above a very small scale is to load the data into an
<span class="caps">OLAP</span> data warehouse and execute your transformations using <span class="caps">SQL</span> (or,
ideally, <a href="https://getdbt.com">dbt</a>).</p>
<p>However, sometimes you need a drop-in solution that can scale-up
dataframe-based&nbsp;transformations. </p>
<p>Traditionally, the usual approach was to use distributed computing
frameworks like Spark or Hadoop to execute dataframe transformations
at scale. However, these require pretty elaborate and complex cloud&nbsp;infrastructure.</p>
<p>These days, there are much better tools for working with big data on a
single machine, using columnar data storage locally like an <span class="caps">OLAP</span>&nbsp;database. </p>
<ul>
<li>
<p>Apache Arrow is a <span class="caps">CSV</span>-alternative typed columnar data storage format
  that enables pandas-alternatives like <a href="https://github.com/pola-rs/polars">polars</a>.</p>
</li>
<li>
<p>duckdb is a sqlite-like dead simple local database that uses
  columnar storage behind the scenes, and can be used as a backend for
  <a href="https://duckdb.org/docs/api/python/spark_api">Spark</a>&nbsp;workflows</p>
</li>
</ul>
<p>I <a href="https://austinweisgrau.github.io/deduplicating-everyaction.html">previously wrote</a> about how at Working Families Party we use duckdb
as the backend for a machine learning identity resolution workflow
(<a href="https://moj-analytical-services.github.io/splink/getting_started.html">splink</a>).</p>
<p>For an overview of the larger trends in cloud computing and big data
transformations, see this really good article by Mother Duck, the
company behind DuckDB: <a href="https://motherduck.com/blog/the-simple-joys-of-scaling-up/">The Simple Joys of Scaling&nbsp;Up</a></p></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        Austin Weisgrau
    </span>
  </span>
<time datetime="2024-10-29T00:00:00-07:00" pubdate>Tue 29 October 2024</time>  <span class="categories">
    <a class='category' href='/category/learning.html'>learning</a>
  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/an-orm-for-google-sheets.html">An ORM for Google Sheets</a>
      </li>
      <li class="post">
          <a href="/tooling-for-big-data-transformations.html">Tooling for Big Data Transformations</a>
      </li>
      <li class="post">
          <a href="/deduplicating-everyaction.html">Deduplicating EveryAction</a>
      </li>
      <li class="post">
          <a href="/migrating-from-civis-to-prefect.html">Migrating from Civis to Prefect</a>
      </li>
      <li class="post">
          <a href="/migrating-to-prefect-part-4-moving-a-script-from-civis-to-prefect.html">Migrating to Prefect, Part 4: Moving a Script from Civis to Prefect</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/learning.html">learning</a></li>
        <li><a href="/category/sharing.html">sharing</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/in/austin-weisgrau-a784b042/" target="_blank">LinkedIn</a></li>
            <li><a href="https://github.com/austinweisgrau" target="_blank">GitHub</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2023&ndash;2025  Austin Weisgrau &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
</body>
</html>